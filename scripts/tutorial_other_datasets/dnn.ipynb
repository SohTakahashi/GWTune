{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare dissimilarity matrices or embeddings from the data\n",
    "First, you need to prepare dissimilarity matrices or embeddings from your data.  \n",
    "To store dissimilarity matrices or embeddings, an instance of the class `Representation` is used.   \n",
    "Please put your dissimilarity matrices or embeddings into the variables `sim_mat` or `embedding` in this instance.   \n",
    "\n",
    "## Load data\n",
    "`DNN`: Latent variables from vision DNNs (ResNet50 and VGG19) for a subset of ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where the instances of \"Representation\" class are included\n",
    "representations = list()\n",
    "data_select = \"DNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset `DNN`\n",
    "The latent features of two vision DNNs(Deep Neural Network), ResNet50 and VGG19, are extracted.   \n",
    "The number of image used for this is 1000 (= 20 class * 50 images), subsampled from the validation set of ImageNet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the category info from label data in the validation dataset.\n",
    "lab_path = '../../data/DNN/label.pt'\n",
    "lab = torch.load(lab_path, weights_only=False).numpy()\n",
    "\n",
    "### category_mat needs to be an one-hot encoding. \n",
    "category_mat = pd.get_dummies(lab)\n",
    "\n",
    "category_mat.columns = np.load('../../data/DNN/label_name.npy')\n",
    "\n",
    "from src.utils.utils_functions import get_category_data, sort_matrix_with_categories \n",
    "object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat = category_mat)\n",
    "\n",
    "model_name_list = ['ResNet50', 'VGG19']\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    \n",
    "    emb_path = f'../../data/DNN/{model_name}_emb.pt'\n",
    "    cos_path = f'../../data/DNN/{model_name}_cosine.pt'\n",
    "    \n",
    "    emb = torch.load(emb_path, weights_only=False).numpy()\n",
    "    sim_mat = torch.load(cos_path, weights_only=False).numpy()\n",
    "    \n",
    "    ### caution!! : If your data are loaded from GPU when using torch.load() before computing `gw_alignment`, the computation may not work properly.\n",
    "    ## You can solve this problem by saving the your data in CPU, like torch.save('your_data'.to(\"cpu\")).\n",
    "\n",
    "    model_rep = Representation(\n",
    "        name=model_name, \n",
    "        sim_mat=sim_mat, \n",
    "        embedding=emb, \n",
    "        get_embedding=False,\n",
    "        object_labels=object_labels,\n",
    "        category_name_list=category_name_list,\n",
    "        category_idx_list=category_idx_list,\n",
    "        num_category_list=num_category_list, \n",
    "        func_for_sort_sim_mat=sort_matrix_with_categories,\n",
    "    )\n",
    "\n",
    "    representations.append(model_rep)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "Second, you need to set the parameters for the optimization of GWOT.    \n",
    "For most of the parameters, you can start with the default values.   \n",
    "However, there are some essential parameters that you need to check for your original applications.  \n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important parameters to check for your application:\n",
    "`eps_list`: The range of the values of epsilon for entropic GWOT.   \n",
    "If epsilon is not in appropriate ranges (if it is too low), the optimization may not work properly.   \n",
    "Although the algorithm will find good epsilon values after many trials, it is a good practice to narrow down the range beforehand.   \n",
    "\n",
    "`num_trial`: The number of trials to test epsilon values from the specified range.   \n",
    "This number directly determines the quality of the unsupervised alignment.   \n",
    "You should set this number high enough to find good local minima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list_tutorial = [1e-4, 1e-2]\n",
    "device = 'cuda' # 'cpu' if GPU is not available\n",
    "to_types = 'torch' # 'numpy'\n",
    "data_type = 'double'\n",
    "multi_gpu = False\n",
    "\n",
    "# whether epsilon is sampled at log scale or not\n",
    "eps_log = True\n",
    "num_trial = 100\n",
    "sinkhorn_method = 'sinkhorn_log'\n",
    "\n",
    "# init_mat_plan = \"random\" # \"uniform\" or \"random\"\n",
    "# sampler_name = \"tpe\"\n",
    "\n",
    "# init_mat_plan = \"uniform\" # \"uniform\" or \"random\"\n",
    "# sampler_name = \"grid\"\n",
    "\n",
    "init_mat_plan = \"random\"\n",
    "sampler_name = \"grid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(    \n",
    "    eps_list = eps_list_tutorial,\n",
    "    eps_log = eps_log, \n",
    "    num_trial = num_trial,\n",
    "    sinkhorn_method=sinkhorn_method, # please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = to_types,\n",
    "    device = device,\n",
    "    data_type = data_type, \n",
    "    \n",
    "    n_jobs = 1,\n",
    "    multi_gpu = multi_gpu, \n",
    "    db_params={\"drivername\": \"sqlite\"},\n",
    "    # db_params={\"drivername\": \"mysql+pymysql\", \"username\": \"root\", \"password\": \"****\", \"host\": \"localhost\"},\n",
    "    \n",
    "    init_mat_plan = init_mat_plan,\n",
    "    \n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    \n",
    "    sampler_name = sampler_name,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Gromov-Wasserstein Optimal Transport (GWOT) between Representations\n",
    "Third, you perform GWOT between the instanses of \"Representation\", by using the class `AlignRepresentations`.  \n",
    "This class has methods for the optimization of entropic Gromov-Wasserstein distance, and the evaluation of the GWOT (Step 4).  \n",
    "This class also has a method to perform conventional Representation Similarity Analysis (RSA).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    config=config,\n",
    "    representations_list=representations,   \n",
    "   \n",
    "    # histogram matching : this will adjust the histogram of target to that of source.\n",
    "    histogram_matching=False,\n",
    "\n",
    "    # main_results_dir : folder or file name when saving the result\n",
    "    # main_results_dir=f\"../../results/{data_select}\",\n",
    "    main_results_dir = \"../../results/random+grid/\" + data_select,\n",
    "   \n",
    "    # data_name : Please rewrite this name if users want to use their own data.\n",
    "    data_name=data_select,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dissimilarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat_format = \"sorted\" # \"sorted\" : the rows and columns of the OT plans are sorted by the coarce categories. If there is no need for sorting, set it to \"default\".\n",
    "visualize_config = VisualizationConfig(\n",
    "    show_figure = True,\n",
    "    fig_ext='svg',\n",
    "    figsize=(12, 12), \n",
    "    title_size=60, \n",
    "    cmap='rocket_r',\n",
    "    font='Arial',\n",
    "    \n",
    "    xlabel='1000 images',\n",
    "    ylabel='1000 images',\n",
    "    cbar_label='cosine distance',\n",
    "    cbar_label_size=60,\n",
    "    \n",
    "    xlabel_size=60,\n",
    "    ylabel_size=60,\n",
    "    \n",
    "    cbar_ticks_size=50,\n",
    "    \n",
    "    ticks=None,\n",
    "    ot_object_tick=False,\n",
    "    ot_category_tick=False,\n",
    "    \n",
    "    # Note that please set ot_category_tick = True when drawing the category line.\n",
    "    draw_category_line=False,\n",
    "    category_line_color='black',\n",
    "    category_line_alpha=0.5,\n",
    "    category_line_style='dashed',\n",
    "    plot_eps_log = eps_log,\n",
    ")\n",
    "\n",
    "visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "\n",
    "sim_mat = align_representation.show_sim_mat(\n",
    "    sim_mat_format=sim_mat_format, \n",
    "    visualization_config=visualize_config,\n",
    "    visualization_config_hist=visualize_hist,\n",
    "    show_distribution=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)\n",
    "This performs a conventional representation similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# The result of RSA for each pair will be stored in align_representation.RSA_corr\n",
    "align_representation.RSA_get_corr(metric=\"pearson\")\n",
    "\n",
    "# print(align_representation.RSA_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GWOT\n",
    "The optimization results are saved in the folder named \"config.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "If you want to change the name of the saved folder, please make changes to \"config.data_name\" and \"representations.name\" (or change the \"filename\" in the code block below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_config.set_params(\n",
    "    figsize=(12, 12), \n",
    "    title_size = 50,\n",
    "    xlabel='1000 images of ResNet50',\n",
    "    ylabel='1000 images of VGG19',\n",
    "    font='Arial',\n",
    "    cbar_label='Probability',\n",
    "    cbar_label_size=40,\n",
    "    cbar_ticks_size=30,\n",
    "    xlabel_size=50,\n",
    "    ylabel_size=50,\n",
    ")\n",
    "\n",
    "align_representation.gw_alignment(\n",
    "    # compute_OT = True,\n",
    "    compute_OT = False,\n",
    "    delete_results = False,\n",
    "    return_data = False,\n",
    "    \n",
    "    ## return_figure : If True, figure of OT will be shown in this notebook. Figure is always saved in the \"figure\" folder.\n",
    "    return_figure = True,\n",
    "    \n",
    "    OT_format = sim_mat_format,\n",
    "    visualization_config = visualize_config,\n",
    "    save_dataframe=True,\n",
    "    change_sampler_seed=True, \n",
    "    sampler_seed = 42, \n",
    "    fix_random_init_seed=True,\n",
    "    \n",
    "    ## parallel_method : user can change the way of parallel computation, \"multiprocess\" or \"multithread\".\n",
    "    # \"multithread\" may be effective for most case, please choose the best one for user's environment.\n",
    "    parallel_method=\"multiprocess\",\n",
    "    \n",
    "    ### caution!! : If your data are loaded from GPU when using torch.load() before computing `gw_alignment`, the multiprocessing may not work properly.\n",
    "    ## You can solve this problem by saving the your data in CPU, like torch.save('your_data'.to(\"cpu\")).\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation and Visualization\n",
    "Finally, you can evaluate and visualize the unsupervise alignment of GWOT.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show how the GWD was optimized\n",
    "`show_optimization_log` will make two figures to show both the relationships between epsilons (x-axis) and GWD (y-axis), and between accuracy (x-axis) and GWD (y-axis).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_config.set_params(\n",
    "    figsize=(10, 8),\n",
    "    cmap='viridis',\n",
    "    font='Arial',\n",
    "    xticks_rotation=0,\n",
    "    cbar_label_size=30,\n",
    "    cbar_ticks_size=20,\n",
    "    title_size=25,\n",
    "    xticks_size=30,\n",
    "    yticks_size=30,\n",
    "    marker_size=60,\n",
    ")\n",
    "\n",
    "align_representation.show_optimization_log(visualization_config=visualize_config) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the accuracy of the unsupervised alignment\n",
    "There are two ways to evaluate the accuracy.  \n",
    "1. Calculate the accuracy based on the OT plan.  \n",
    "For using this method, please set the parameter `eval_type = \"ot_plan\"` in \"calc_accuracy()\".   \n",
    "  \n",
    "2. Calculate the matching rate based on the k-nearest neighbors of the embeddings.   \n",
    "For using this method, please set the parameter `eval_type = \"k_nearest\"` in \"calc_accuracy()\".   \n",
    "\n",
    "For both cases, the accuracy evaluation criterion can be adjusted by setting `top_k_list`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy based on the OT plan. \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)\n",
    "\n",
    "\"\"\"\n",
    "uniform + grid\n",
    "Top k accuracy : \n",
    "        ResNet50_vs_VGG19\n",
    "top_n                   \n",
    "1                   29.8\n",
    "5                   59.0\n",
    "10                  73.5\n",
    "\n",
    "random + TPE\n",
    "Top k accuracy : \n",
    "        ResNet50_vs_VGG19\n",
    "top_n                   \n",
    "1                   30.2\n",
    "5                   58.7\n",
    "10                  73.3\n",
    "\n",
    "\n",
    "random + grid\n",
    "Top k accuracy : \n",
    "        ResNet50_vs_VGG19\n",
    "top_n                   \n",
    "1                   30.1\n",
    "5                   58.5\n",
    "10                  73.5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\", metric=\"cosine\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calclate the category level accuracy\n",
    "# If the data has the coarse category labels, you can observe the category level accuracy.\n",
    "# This accuracy is calculated based on the OT plan.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"category\", category_mat=category_mat)\n",
    "align_representation.plot_accuracy(eval_type = \"category\", scatter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Procrustes Analysis\n",
    "Using optimized transportation plans, you can align the embeddings of each representation to a shared space in an unsupervised manner.  \n",
    "The `\"pivot\"` refers to the target embeddings space to which the other embeddings will be aligned.   \n",
    "You have the option to designate the `\"pivot\"` as one of the representations or the barycenter.  \n",
    "Please ensure that 'pair_number_list' includes all pairs between the pivot and the other Representations.  \n",
    "\n",
    "If you wish to utilize the barycenter, please make use of the method `AlignRepresentation.barycenter_alignment()`.  \n",
    "You can use it in the same manner as you did with `AlignRepresentation.gw_alignment()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For here, we use the embeddings for the 6 categories below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the category info from label data in the validation dataset.\n",
    "lab_path = '../../data/DNN/label.pt'\n",
    "lab = torch.load(lab_path, weights_only=False).to('cpu').numpy()\n",
    "\n",
    "### category_mat needs to be an one-hot encoding. \n",
    "category_mat = pd.get_dummies(lab)\n",
    "\n",
    "category_mat.columns = np.load('../../data/DNN/label_name.npy')\n",
    "\n",
    "category_name_list = ['tench', 'tiger', 'goldfish', 'house', 'jay', 'bulbul']\n",
    "\n",
    "object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_name = \"PCA\" #\"TSNE\", \"PCA\", \"MDS\"\n",
    "dim = 3\n",
    "visualization_embedding = VisualizationConfig(\n",
    "    fig_ext='svg',\n",
    "    font='Arial',\n",
    "    figsize=(10, 10), \n",
    "    xlabel=\"PC1\",\n",
    "    ylabel=\"PC2\", \n",
    "    zlabel=\"PC3\",\n",
    "    marker_size=50,\n",
    "    xlabel_size=40,\n",
    "    ylabel_size=40,\n",
    "    zlabel_size=40,\n",
    "    legend_size=20,\n",
    ")\n",
    "\n",
    "align_representation.visualize_embedding(\n",
    "    dim=dim,\n",
    "    method=emb_name,\n",
    "    pivot=0,\n",
    "    visualization_config=visualization_embedding,\n",
    "    category_name_list=category_name_list, \n",
    "    category_idx_list=category_idx_list, \n",
    "    num_category_list=num_category_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Option) Visualize the aligned embeddings\n",
    "It is helpful to visually inspect the quality of the unsupervised alignment by plotting the aligned embeddings in 2D or 3D space. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the optimal transportation plan $\\Gamma∗$, one set of embeddings $X$, \n",
    "and the other set of aligned embeddings are obtained by performing matrix product of the $\\Gamma*$ and $X$. \n",
    "\n",
    "This $\\Gamma* X$ means the new embedding to represent the other set of embedding $Y$ in the space of $X$. \n",
    "\n",
    "Next, the embedding of $X$ and new embedding of $Y$ ($Γ∗X$) in the space of $X$ are concatenated in the axis of the number of embeddings (e.g. experimental stimuli, and so on).  \n",
    "Then, for example, Principle Components Analysis (PCA) is used to project high-dimensional embeddings into 2D or 3D space, but other dimensionality reduction methods are also applicable. \n",
    "\n",
    "And, each one of the two embeddings were plotted in 3D figure after splitting the data into the two embeddings. \n",
    "If there is a known correspondence between the embeddings, the user can visually check whether the aligned embeddings are positioned close to the corresponding embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = align_representation.pairwise_list[0]\n",
    "\n",
    "ot = pair.OT\n",
    "\n",
    "# plt.imshow(ot, cmap='viridis')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pair.source.embedding\n",
    "target = pair.target.embedding\n",
    "\n",
    "new_source = pair.OT.T @ target * len(target)\n",
    "new_target = pair.OT @ source * len(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rep_list = [\n",
    "    Representation(name=\"ResNet50\", embedding=source),\n",
    "    Representation(name=\"VGG19\", embedding=new_target),\n",
    "]\n",
    "\n",
    "ar = AlignRepresentations(\n",
    "    config=config,\n",
    "    representations_list=new_rep_list,\n",
    "    histogram_matching=False,\n",
    "    main_results_dir=f\"../../results/{data_select}\",\n",
    "    data_name=data_select,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_name = \"PCA\" #\"TSNE\", \"PCA\", \"MDS\"\n",
    "dim = 3\n",
    "visualization_embedding = VisualizationConfig(\n",
    "    fig_ext='svg',\n",
    "    figsize=(10, 10), \n",
    "    xlabel=\"PC1\",\n",
    "    ylabel=\"PC2\", \n",
    "    zlabel=\"PC3\",\n",
    "    marker_size=50,\n",
    "    xlabel_size=40,\n",
    "    ylabel_size=40,\n",
    "    zlabel_size=40,\n",
    "    legend_size=20,\n",
    ")\n",
    "\n",
    "ar.visualize_embedding(\n",
    "    dim=dim,\n",
    "    method=emb_name,\n",
    "    pivot=None,\n",
    "    visualization_config=visualization_embedding,\n",
    "    category_name_list=category_name_list, \n",
    "    category_idx_list=category_idx_list, \n",
    "    num_category_list=num_category_list,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
